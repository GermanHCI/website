
@inproceedings{henning2022standing,
title = {Standing out among the daily spam: How to catch website owners' attention by means of vulnerability notifications},
author = {Anne Hennig (Karlsruhe Institute of Technology) and Fabian Neusser (University of Bamberg) and Aleksandra Pawelek (Karlsruhe Institute of Technology) and Dominik Herrmann (University of Bamberg) and Peter Mayer (Karlsruhe Institute of Technology)},
url = {https://secuso.aifb.kit.edu
https://www.youtube.com/watch?v=d3Qe36Ts4Gk (Teaser Video)},
doi = {https://doi.org/10.1145/3491101.3519847},
year  = {2022},
date = {2022-05-01},
urldate = {2022-05-01},
publisher = {ACM},
series = {ACM CHI},
abstract = {Running a business without having a website is nearly impossible nowadays. Most business owners use content managements systems to manage their websites. Yet, those can pose security risks and provide vulnerabilities for manipulations. With vulnerability notifications, website owners are notified about security risks. To identify common themes with respect to vulnerability notifications and provide deeper insight into the motivations of website owners to react to those notifications, we conducted 25 semi-structured interviews. In compliance with previous research, we could confirm that distrust in unexpected notifications is high and, in contrast to previous research, we suggest that verification possibilities are the most important factors to establish trust in notifications. We also endorse the findings that raising awareness for the severity and the complexity of the problems is crucial to increase remediation rates.},
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{Lagner2022EyeMeet,
title = {EyeMeet: A Joint Attention Support System for Remote Meetings},
author = {Moritz Langner (KIT) and Peyman Toreini (KIT) and Alexander Maedche (KIT)},
url = {https://issd.iism.kit.edu/
https://www.instagram.com/kit_information_systems/},
doi = {https://doi.org/10.1145/3491101.3519792},
year  = {2022},
date = {2022-05-01},
publisher = {ACM},
abstract = {A major challenge in remote meetings is that awareness cues, such as gaze, become degraded despite playing a crucial role in communication and establishing joint attention. Eye tracking allows overcoming these obstacles by enabling augmentation of remote meetings with gaze information. In this project, we followed a participatory approach by first distributing a scenario-based survey to students (n=79) to uncover their preference of eye-based joint attention support (real-time, retrospective, real-time & retrospective, no) for remote university meetings. Building on these findings, we developed EyeMeet, an eye-based joint attention support system that combines state-of-the-art real-time joint attention support with a retrospective attention feedback for remote meetings. In a four-week study, two student groups worked remotely on course assignments using EyeMeet. Our findings of the study highlight that EyeMeets supports students in staying more focused on the meetings. Complementing real-time joint attention support, retrospective joint attention feedback is recognized to provide valuable support for reflecting and adapting behavior for upcoming meetings.},
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}

@inproceedings{Ruoff2022onyx,
title = {ONYX - User Interfaces for Assisting in Interactive Task Learning for Natural Language Interfaces of Data Visualization Tools},
author = {Marcel Ruoff (KIT) and Brad Myers (CMU) and Alexander Maedche (KIT)},
url = {https://issd.iism.kit.edu/
https://www.instagram.com/kit_information_systems/},
doi = {https://doi.org/10.1145/3491101.3519793},
year  = {2022},
date = {2022-05-01},
publisher = {ACM},
abstract = {While natural language interfaces (NLIs) are increasingly utilized to simplify the interaction with data visualization tools, improving and adapting the NLIs to the individual needs of users still requires the support of developers. ONYX introduces an interactive task learning (ITL) based approach which enables NLIs to learn from users through natural interactions. Users can personalize the NLI with new commands using direct manipulation, known commands, or by combining both. To further support users during the training process, we derived two design goals for the user interface, namely providing suggestions based on sub-parts of the command and addressing ambiguities through follow-up questions and instantiated them in ONYX. In order to trigger reflections and gain feedback on possible design trade-offs of ONYX and the instantiated design goals, we performed a formative user study to understand how to successfully integrate the suggestions and follow-up question into the interaction.},
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022NittalaStepsOnSkinDevices,
title = {Next Steps in Epidermal Computing: Opportunities and Challenges for Soft On-Skin Devices},
author = {Aditya Shekhar Nittala (Saarland University) and Jürgen Steimle (Saarland University)},
url = {https://hci.cs.uni-saarland.de/, Website Lab},
doi = {10.1145/3491102.3517668},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
publisher = {ACM},
abstract = {Skin is a promising interaction medium and has been widely explored for mobile, and expressive interaction. Recent research in HCI has seen the development of Epidermal Computing Devices: ultra-thin and non-invasive devices which reside on the user's skin, offering intimate integration with the curved surfaces of the body, while having physical and mechanical properties that are akin to skin, expanding the horizon of on-body interaction. However, with rapid technological advancements in multiple disciplines, we see a need to synthesize the main open research questions and opportunities for the HCI community to advance future research in this area. By systematically analyzing Epidermal Devices contributed in the HCI community, physical sciences research and from our experiences in designing and building Epidermal Devices, we identify opportunities and challenges for advancing research across five themes. This multi-disciplinary synthesis enables multiple research communities to facilitate progression towards more coordinated endeavors for advancing Epidermal Computing.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022GuentherSmooth,
title = {Smooth as Steel Wool: Effects of Visual Stimuli on the Haptic Perception of Roughness in Virtual Reality},
author = {Sebastian Günther (TU Darmstadt) and Julian Rasch (LMU München) and Dominik Schön (TU Darmstadt) and Florian Müller (LMU München) and Martin Schmitz (TU Darmstadt) and Jan Riemann (TU Darmstadt) and Andrii Matviienko (TU Darmstadt) and Max Mühlhäuser (LMU München)},
url = {https://sebastian-guenther.com/, Website Author
https://www.teamdarmstadt.de, Website - Telecooperation Lab Darmstadt
https://www.youtube.com/watch?v=glEOP48qVCE, YouTube - Teaser Video
https://www.youtube.com/watch?v=9q6zZCJ9rLg, YouTube - Video Figure},
doi = {10.1145/3491102.3517454},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
publisher = {ACM},
abstract = {"Haptic Feedback is essential for lifelike Virtual Reality (VR) experiences. To provide a wide range of matching sensations of being touched or stroked, current approaches typically need large numbers of different physical textures. However, even advanced devices can only accommodate a limited number of textures to remain wearable. Therefore, a better understanding is necessary of how expectations elicited by different visualizations affect haptic perception, to achieve a balance between physical constraints and great variety of matching physical textures. 

In this work, we conducted an experiment (N=31) assessing how the perception of roughness is affected within VR. We designed a prototype for arm stroking and compared the effects of different visualizations on the perception of physical textures with distinct roughnesses. Additionally, we used the visualizations' real-world materials, no-haptics and vibrotactile feedback as baselines. As one result, we found that two levels of roughness can be sufficient to convey a realistic illusion."},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022MuenderOrganTangibles,
title = {Evaluating Soft Organ-Shaped Tangibles for Medical Virtual Reality},
author = {Thomas Muender (Digital Media Lab, University of Bremen) and Anke Reinschluessel (Digital Media Lab, University of Bremen) and Daniela Salzmann (University Hospital for Visceral Surgery, Carl von Ossietzky University of Oldenburg, PIUS-Hospital) and Thomas Lück (cirp GmbH) and Andrea Schenk (Fraunhofer Institute for Digital Medicine MEVIS) and Dirk Weyhe (University Hospital for Visceral Surgery, Carl von Ossietzky University of Oldenburg, PIUS-Hospital) and Tanja Döring (Digital Media Lab, University of Bremen) and Rainer Malaka (Digital Media Lab, University of Bremen)},
url = {dm.tzi.de/, Website Digital Media Lap Bremen
https://twitter.com/dmlabbremen, Twitter},
doi = {10.1145/3491101.3519715},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Connecting digital information with the physical is one of the essential ideas of tangible user interfaces. The design of the physical representation is important especially for specialised domains like surgery planning, because surgeons rely heavily on their tactile senses. Therefore, this research work investigates the effect of a soft and a hard 3D model as an interaction device for virtual reality surgical planning. A user study with 13 surgeons reveals a clear preference for the softer, more realistic material and a significantly higher haptic user experience for the soft model compared to the hard one. These results advocate for stressing material aspects along with the interaction design in domains with an inherently high focus on tactile aspects.},
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022LuoPlacement,
title = {Where Should We Put It? Layout and Placement Strategies of Documents in Augmented Reality for Collaborative Sensemaking},
author = {Weizhou Luo (Interactive Media Lab Dresden, Technische Universität Dresden) and Anke Lehmann (Interactive Media Lab Dresden, Technische Universität Dresden) and Hjalmar Widengren (Interactive Media Lab Dresden, Technische Universität Dresden) and Raimund Dachselt (Interactive Media Lab Dresden, Technische Universität Dresden; Cluster of Excellence Physics of Life, Technische Universität Dresden; Centre for Tactile Internet with Human-in-the-Loop (CeTI), Technische Universität Dresden)},
url = {https://imld.de/en/, Website Interactive Media Lab Dresden
https://www.youtube.com/user/imldresden, YouTube
https://twitter.com/imldresden, Twitter
https://youtu.be/rW9u5-WkuMM, YouTube - Teaser Video
https://youtu.be/fCVpxu4tzDw, YouTube - Video Figure},
doi = {10.1145/3491102.3501946},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Future offices are likely reshaped by Augmented Reality (AR) extending the display space while maintaining awareness of surroundings, and thus promise to support collaborative tasks such as brainstorming or sensemaking. However, it is unclear how physical surroundings and co-located collaboration influence the spatial organization of virtual content for sensemaking.Therefore, we conducted a study (N=28) to investigate the effect of office environments and work styles during a document classification task using AR with regard to content placement, layout strategies, and sensemaking workflows. Results show that participants require furniture, especially tables and whiteboards, to assist sensemaking and collaboration regardless of room settings, while generous free spaces (e.g., walls) are likely used when available. Moreover, collaborating participants tend to use furniture despite personal layout preferences. We identified different placement and layout strategies, as well as the transitions in-between. Finally, we propose design implications for future immersive sensemaking applications and beyond.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022MarkyVoting,
title = {Investigating Usability and User Experience of Individually Verifiable Internet Voting Schemes},
author = {Karola Marky (Technical University of Darmstadt, University of Glasgow, Lilybank Gardens, Glasgow, United Kingdom) and Marie Laure Zollinger (University of Luxembourg, Esch-sur-Alzette, Luxembourg) and Peter B. Roenne (University of Luxembourg, Esch-sur-Alzette, Luxembourg) and Peter Y. A. Ryan (University of Luxembourg, Esch-sur-Alzette, Luxembourg) and Tim Grube (Technical University of Darmstadt, Darmstadt, Germany) and Kai Kunze (Keio University, Kohoku-ku, Yokohama, Japan)},
url = {https://teamdarmstadt.de/, Website Telecooperation Lab Darmstadt},
doi = {10.1145/3459604},
year  = {2022},
date = {2022-04-30},
abstract = {Internet voting can afford more inclusive and inexpensive elections. The flip side is that the integrity of the election can be compromised by adversarial attacks and malfunctioning voting infrastructure. Individual verifiability aims to protect against such risks by letting voters verify that their votes are correctly registered in the electronic ballot box. Therefore, voters need to carry out additional tasks making human factors crucial for security. In this article, we establish a categorization of individually verifiable Internet voting schemes based on voter interactions. For each category in our proposed categorization, we evaluate a voting scheme in a user study with a total of 100 participants. In our study, we assessed usability, user experience, trust, and further qualitative data to gain deeper insights into voting schemes. Based on our results, we conclude with recommendations for developers and policymakers to inform the choices and design of individually verifiable Internet voting schemes.},
keywords = {Journal},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022ParkFoolProofJoint,
title = {FoolProofJoint: Reducing Assembly Errors of Laser Cut 3D Models by Means of Custom Joint Patterns},
author = {Keunwoo Park (Hasso Plattner Institute, Potsdam, Germany) and Conrad Lempert (Hasso Plattner Institute, Potsdam, Germany) and Muhammad Abdullah (Hasso Plattner Institute, Potsdam, Germany) and Shohei Katakura (Hasso Plattner Institute, Potsdam, Germany) and Jotaro Shigeyama (Hasso Plattner Institute, Potsdam, Germany) and Thijs Roumen (Hasso Plattner Institute, Potsdam, Germany) and Patrick Baudisch (Hasso Plattner Institute, Potsdam, Germany)},
url = {https://hpi.de/baudisch/home.html, Website HCI Lab Potsdam},
doi = {10.1145/3491102.3501919},
year  = {2022},
date = {2022-04-30},
abstract = {We present FoolProofJoint, a software tool that simplifies the assembly of laser-cut 3D models and reduces the risk of erroneous assembly. FoolProofJoint achieves this by modifying finger joint patterns. Wherever possible, FoolProofJoint makes similar looking pieces fully interchangeable, thereby speeding up the user’s visual search for a matching piece. When that is not possible, FoolProofJoint gives finger joints a unique pattern of individual fingers widths so as to fit only with the correct joint on the correct piece, thereby preventing erroneous assembly. In our benchmark set of 217 laser-cut 3D models downloaded from kyub.com, FoolProofJoint made groups of similar looking pieces fully interchangeable for 65% of all groups of similar pieces; FoolProofJoint fully prevented assembly mistakes for 97% of all models.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022EngertStraide,
title = {STRAIDE: A Research Platform for Shape-Changing Spatial Displays based on Actuated Strings},
author = {Severin Engert (Technische Universität Dresden) and Konstantin Klamka (Technische Universität Dresden) and Andreas Peetz (Technische Universität Dresden) and Raimund Dachselt (Technische Universität Dresden)},
url = {https://imld.de, Website Interactive Media Lab Dresden
https://twitter.com/imldresden, Twitter
https://www.youtube.com/watch?v=AQRS6ko4Z8s, YouTube - Teaser Video
https://www.youtube.com/watch?v=t-R04SkK6vs, YouTube - Video Figure},
doi = {10.1145/3491102.3517462},
year  = {2022},
date = {2022-04-30},
abstract = {We present STRAIDE, a string-actuated interactive display environment that allows to explore the promising potential of shape-changing interfaces for casual visualizations. At the core, we envision a platform that spatially levitates elements to create dynamic visual shapes in space. We conceptualize this type of tangible mid-air display and discuss its multifaceted design dimensions. Through a design exploration, we realize a physical research platform with adjustable parameters and modular components. For conveniently designing and implementing novel applications, we provide developer tools ranging from graphical emulators to in-situ augmented reality representations. To demonstrate STRAIDE's reconfigurability, we further introduce three representative physical setups as a basis for situated applications including ambient notifications, personal smart home controls, and entertainment. They serve as a technical validation, lay the foundations for a discussion with developers that provided valuable insights, and encourage ideas for future usage of this type of appealing interactive installation.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022WindlAutomating,
title = {Automating Contextual Privacy Policies: Design and Evaluation of a Production Tool for Digital Consumer Privacy Awareness},
author = {Maximiliane Windl (LMU Munich) and Niels Henze (University of Regensburg) and Albrecht Schmidt (LMU Munich) and Sebastian S. Feger (LMU Munich)},
url = {https://maximiliane-windl.com/, Website Author
https://www.facebook.com/maximiliane.pauline/, Facebook Author
https://www.linkedin.com/in/maximiliane-windl-8889b6195/, LinkedIn Author
https://youtu.be/uCFj_nBdzsk, YouTube - Teaser Video},
doi = {10.1145/3491102.3517688},
year  = {2022},
date = {2022-04-30},
abstract = {Users avoid engaging with privacy policies because they are lengthy and complex, making it challenging to retrieve relevant information. In response, research proposed contextual privacy policies (CPPs) that embed relevant privacy information directly into their affiliated contexts. To date, CPPs are limited to concept showcases. This work evolves CPPs into a production tool that automatically extracts and displays concise policy information. We first evaluated the technical functionality on the US's 500 most visited websites with 59 participants. Based on our results, we further revised the tool to deploy it in the wild with 11 participants over ten days. We found that our tool is effective at embedding CPP information on websites. Moreover, we found that the tool's usage led to more reflective privacy behavior, making CPPs powerful in helping users understand the consequences of their online activities. We contribute design implications around CPP presentation to inform future systems design.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022WindlDiscovery,
title = {It Is Not Always Discovery Time: Four Pragmatic Approaches in Designing AI Systems},
author = {Maximiliane Windl (LMU Munich) and Sebastian S. Feger (LMU Munich) and Lara Zijlstra (Utrecht University) and Albrecht Schmidt (LMU Munich) and Paweł W. Woźniak (Chalmers University of Technology)},
url = {https://maximiliane-windl.com/, Website Author
https://www.facebook.com/maximiliane.pauline/, Facebook Author
https://www.linkedin.com/in/maximiliane-windl-8889b6195/, LinkedIn Author
https://www.youtube.com/watch?v=BlU4IuoCn-s, YouTube - Teaser Video},
doi = {10.1145/3491102.3501943},
year  = {2022},
date = {2022-04-30},
abstract = {While systems that use Artificial Intelligence (AI) are increasingly becoming part of everyday technology use, we do not fully understand how AI changes design processes. A structured understanding of how designers work with AI is needed to improve the design process and educate future designers. To that end, we conducted interviews with designers who participated in projects which used AI. While past work focused on AI systems created by experienced designers, we focus on the perspectives of a diverse sample of interaction designers. Our results show that the design process of an interactive system is affected when AI is integrated and that design teams adapt their processes to accommodate AI. Based on our data, we contribute four approaches adopted by interaction designers working with AI: a priori, post-hoc, model-centric, and competence-centric. Our work contributes a pragmatic account of how design processes for AI systems are enacted.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022DreyCollaborative,
title = {Towards Collaborative Learning in Virtual Reality: A Comparison of Co-Located Symmetric and Asymmetric Pair-Learning},
author = {Tobias Drey (Institute of Media Informatics, Ulm University) and Patrick Albus (Institute of Psychology + Education, Ulm University) and Simon der Kinderen (Institute of Media Informatics, Ulm University) and Maximilian Milo (Institute of Media Informatics, Ulm University) and Thilo Segschneider (Institute of Media Informatics, Ulm University) and Linda Chanzab (Institute of Media Informatics, Ulm University) and Michael Rietzler (Institute of Media Informatics, Ulm University) and Tina Seufert (Institute of Psychology + Education, Ulm University) and Enrico Rukzio (Institute of Media Informatics, Ulm University)},
url = {https://www.uni-ulm.de/en/in/mi/institute/staff/tobias-drey/, Website Author
https://twitter.com/TobiasDrey, Twitter Author
https://www.linkedin.com/in/tobias-drey-ulm/, LinkedIn Author
https://www.youtube.com/watch?v=6og_BFyI-gM, YouTube - Teaser Video
https://www.youtube.com/watch?v=_m32zfsjWcY, YouTube - Video Figure},
doi = {10.1145/3491102.3517641},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Pair-learning is beneficial for learning outcome, motivation, and social presence, and so is virtual reality (VR) by increasing immersion, engagement, motivation, and interest of students. Nevertheless, there is a research gap if the benefits of pair-learning and VR can be combined. Furthermore, it is not clear which influence it has if only one or both peers use VR. To investigate these aspects, we implemented two types of VR pair-learning systems, a symmetric system with both peers using VR and an asymmetric system with one using a tablet. In a user study (N=46), the symmetric system statistically significantly provided higher presence, immersion, player experience, and lower intrinsic cognitive load, which are all important for learning. Symmetric and asymmetric systems performed equally well regarding learning outcome, highlighting that both are valuable learning systems. We used these findings to define guidelines on how to design co-located VR pair-learning applications, including characteristics for symmetric and asymmetric systems.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022AbdrabouPasswordReuse,
title = {"Your Eyes Tell You Have Used This Password Before": Identifying Password Reuse from Gaze and Keystroke Dynamics},
author = {Yasmeen Abdrabou (Bundeswehr University Munich, University of Glasgow) and Johannes Schütte (Bundeswehr University Munich) and Ahmed Shams (Fatura LLC Egypt) and Ken Pfeuffer (Aarhus University, Bundeswehr University Munich) and Daniel Buschek (University of Bayreuth) and Mohamed Khamis (University of Glasgow) and Florian Alt (Bundeswehr University Munich)},
url = {https://www.unibw.de/usable-security-and-privacy-en, Website Lab
https://youtu.be/22eRF52FLdo, YouTube - Teaser Video
https://youtu.be/_5UfR7GUoXk, YouTube - Video Figure},
doi = {10.1145/3491102.3517531},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {A significant drawback of text passwords for end-user authentication is password reuse. We propose a novel approach to detect password reuse by leveraging gaze as well as typing behavior and study its accuracy. We collected gaze and typing behavior from 49 users while creating accounts for 1) a webmail client and 2) a news website. While most participants came up with a new password, 32% reported having reused an old password when setting up their accounts. We then compared different ML models to detect password reuse from the collected data. Our models achieve an accuracy of up to 87.7% in detecting password reuse from gaze, 75.8% accuracy from typing, and 88.75% when considering both types of behavior. We demonstrate that revised{using gaze, password} reuse can already be detected during the registration process, before users entered their password. Our work paves the road for developing novel interventions to prevent password reuse.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022PrangeWhere,
title = {"Where did you first meet the owner?'' -- Exploring Usable Authentication for Smart Home Visitors},
author = {Sarah Prange (University of the Bundeswehr Munich, LMU Munich) and Sarah Delgado Rodriguez (University of the Bundeswehr Munich) and Timo Döding (LMU Munich) and Florian Alt (University of the Bundeswehr Munich)},
url = {https://www.unibw.de/usable-security-and-privacy-en, Website Lab
https://youtu.be/H0YO1qGIOWI, YouTube - Teaser Video
https://youtu.be/k6trjm5mjUA, YouTube - Video Figure},
doi = {10.1145/3491101.3519777},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Visitors in smart homes might want to use certain device features, as far as permitted by the device owner (e.g., streaming music on a smart speaker). At the same time, protecting access to features from attackers is crucial, motivating a need for authentication. However, it is unclear if and how smart home visitors should authenticate as they usually do not have access to respective interfaces. We explore considerations for the design of authentication for visitors evolving around, e.g., the visitors themselves as well as the environment and concrete mechanisms. Moreover, we suggest a concrete idea: security questions to authenticate visitors in smart homes.
In an interview study (N=24), we found that owners and visitors appreciated the low effort and would adapt our approach. We conclude with future research directions that we hope will spark further discussions around the design of authentication for smart homes, considering visitors and owners alike.},
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022VolkPriCheck,
title = {PriCheck - An Online Assistant for Smart Device Purchases},
author = {Vera Volk (LMU Munich) and Sarah Prange (University of the Bundeswehr Munich, LMU Munich) and Florian Alt (University of the Bundeswehr Munich)},
url = {https://www.unibw.de/usable-security-and-privacy-en, Website Lab
https://youtu.be/-3qFDn_tOY4, YouTube - Teaser Video
https://youtu.be/fIx26wEews4, YouTube - Video Figure},
doi = {10.1145/3491101.3519827},
year  = {2022},
date = {2022-04-30},
abstract = {In this paper, we present PriCheck, a browser extension that provides privacy-relevant information about smart devices (e.g., in an online shop). This information is oftentimes hidden, difficult to access, and, thus, often neglected when buying a new device. With PriCheck, we enable users to make informed purchase decisions. We conducted an exploratory study using the browser extension in a simplified (mock) online shop for smart devices. Participants chose devices with and without using the extension. We found that participants (N = 11) appreciated the usability and available information of PriCheck, helping them with informed decisions for privacy-preserving products. We hope our work will stimulate further discussion on how to make privacy information for novel products available, understandable, and easy to access for users.},
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022SpielADHD,
title = {ADHD and Technology Research -- Investigated by Neurodivergent Readers},
author = {Katta Spiel (Human-Computer Interaction Group, TU Wien) and Eva Hornecker (Bauhaus-Universität Weimar) and Rua Mae Williams (University of Florida) and Judith Good (University of Sussex)},
url = {https://www.uni-weimar.de/en/media/chairs/computer-science-department/human-computer-interaction/, Website Lab},
doi = {10.1145/3411764.3445196},
year  = {2022},
date = {2022-04-30},
abstract = {Technology research for neurodivergent conditions is largely shaped by research aims which privilege neuro-normative outcomes. As such, there is an epistemic imbalance in meaning making about these technologies. We conducted a critical literature review of technologies designed for people with ADHD, focusing on how ADHD is framed, the research aims and approaches, the role of people with ADHD within the research process, and the types of systems being developed within Computing and HCI. Our analysis and review is conducted explicitly from an insider perspective, bringing our perspectives as neurodivergent researchers to the topic of technologies in the context of ADHD. We found that 1) technologies are largely used to `mitigate' the experiences of ADHD which are perceived as disruptive to neurotypical standards of behaviour; 2) little HCI research in the area invites this population to co-construct the technologies or to leverage neurodivergent experiences in the construction of research aims; and 3) participant resistance to deficit frames can be read within the researchers' own accounts of participant actions. We discuss the implications of this status quo for disabled people and technology researchers alike, and close with a set of recommendations for future work in this area. },
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022MarchettiPetRobot,
title = {Pet-Robot or Appliance? Care Home Residents with Dementia Respond to a Zoomorphic Floor Washing Robot},
author = {Emanuela Marchetti (SDU Syddansk Universitet, Odense, Denmark) and Sophie Grimme (OFFIS Oldenburg, Bauhaus-Universität Weimar) and Eva Hornecker (Bauhaus-Universität Weimar) and Avgi Kollakidou (Mærsk Mc-Kinney Møller Institute, University of Southern Denmark, Odense, Denmark) and Philipp Graf (TU Chemnitz)},
url = {https://www.uni-weimar.de/en/media/chairs/computer-science-department/human-computer-interaction/, Website Lab},
doi = {10.1145/3491102.3517463},
year  = {2022},
date = {2022-04-30},
abstract = {Any active entity that shares space with people is interpreted as a social actor. Based on this notion, we explore how robots that integrate functional utility with a social role and character can integrate meaningfully into daily practice. Informed by interviews and observations, we designed a zoomorphic floor cleaning robot which playfully interacts with care home residents affected by dementia. A field study shows that playful interaction can facilitate the introduction of utilitarian robots in care homes, being nonthreatening and easy to make sense of. Residents previously reacted with distress to a Roomba robot, but were now amused by and played with our cartoonish cat robot or simply tolerated its presence. They showed awareness of the machine-nature of the robot, even while engaging in pretend-play. A playful approach to the design of functional robots can thus explicitly conceptualize such robots as social actors in their context of use.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022StemasovShapeFindAR,
title = {ShapeFindAR: Exploring In-Situ Spatial Search for Physical Artifact Retrieval using Mixed Reality },
author = {Evgeny Stemasov (Institute of Media Informatics, Ulm University) and Tobias Wagner (Institute of Media Informatics, Ulm University) and Jan Gugenheimer (Télécom Paris - LTCI, Institut Polytechnique de Paris) and Enrico Rukzio (Institute of Media Informatics, Ulm University)},
url = {https://www.uni-ulm.de/in/mi/hci/, Website Lab
https://twitter.com/mi_uulm, Twitter Lab
https://youtu.be/mVcBzLaWuPs, YouTube - Teaser Video
https://youtu.be/rc2JNFkAHx0, YouTube - Video Figure},
doi = {10.1145/3491102.3517682},
year  = {2022},
date = {2022-04-30},
abstract = {Personal fabrication is made more accessible through repositories like Thingiverse, as they replace modeling with retrieval. However, they require users to translate spatial requirements to keywords, which paints an incomplete picture of physical artifacts: proportions or morphology are non-trivially encoded through text only. We explore a vision of in-situ spatial search for (future) physical artifacts, and present ShapeFindAR, a mixed-reality tool to search for 3D-models using in-situ sketches blended with textual queries. With ShapeFindAR, users search for geometry, and not necessarily precise labels, while coupling the search process to the physical environment (e.g., by sketching in-situ, extracting search terms from objects present, or tracing them). We developed ShapeFindAR for HoloLens 2, connected to a database of 3D-printable artifacts. We specify in-situ spatial search, describe its advantages, and present walkthroughs using ShapeFindAR, which highlight novel ways for users to articulate their wishes, without requiring complex modeling tools or profound domain knowledge.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022LiBalancing,
title = {Towards Balancing Real-World Awareness and VR Immersion in Mobile VR},
author = {Jingyi Li (LMU Munich) and Filippe Frulli (LMU Munich) and Stella Clarke (BMW Group) and Andreas Butz (LMU Munich)},
url = {http://www.medien.ifi.lmu.de, Website Lab
https://www.facebook.com/LMU.Medieninformatik/, Facebook Lab
https://youtu.be/_9gnVLokT70, YouTube - Video Figure},
doi = {10.1145/3491101.3519824},
year  = {2022},
date = {2022-04-30},
abstract = {Virtual Reality (VR) can be used to create immersive infotainment experiences for car passengers. However, not much is known about how to best incorporate the essentials of their surroundings for balancing real-world awareness and immersion. To address this gap, we explored 2D and 3D visual cues of the rear-seat space to notify passengers about different real-world tasks (lower armrest, take cup, close window, and hold handle) during a first-person game in VR. Results from our pilot study (n=19) show that users perceive a lower workload in the task hold handle than all other tasks. They also feel more immersed in VR after completing this task, compared to take cup and close window. Based on our findings, we propose real-world task types, synchronous visual cues, and various input and transition approaches as promising future research directions.},
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022CalepsocARdLearner,
title = {cARdLearner: Using Expressive Virtual Agents when Learning Vocabulary in Augmented Reality},
author = {Aimée Sousa Calepso (University of Stuttgart) and Natalie Hube (University of Stuttgart) and Noah Berenguel Senn (University of Stuttgart) and Vincent Brandt (University of Stuttgart) and Michael Sedlmair (University of Stuttgart)},
url = {https://www.visus.uni-stuttgart.de/institut/team/arbeitsgruppe/arbeitsgruppe-prof.-sedlmair/, Website Lab
https://visvar.github.io/, Website Visvar},
doi = {10.1145/3491101.3519631},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Augmented reality (AR) has a diverse range of applications, including language teaching. When studying a foreign language, one of the biggest challenges learners face is memorizing new vocabulary. While augmented holograms are a promising means of supporting this memorization process, few studies have explored their potential in the language learning context. We demonstrate the possibility of using flashcard along with an expressive holographic agent  on vocabulary learning. Users scan a flashcard and play an animation that is connected with an emotion related to the word they are seeing. Our goal is to propose an alternative to the traditional use of flashcards, and also introduce another way of using AR in the association process.},
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022HubeAvatars,
title = {Using Expressive Avatars to Increase Emotion Recognition: A Pilot Study},
author = {Natalie Hube (Mercedes-Benz AG, University of Stuttgart) and Kresimir Vidackovic (Hochschule der Medien, University of Applied Sciences) and Michael Sedlmair (University of Stuttgart)},
url = {https://www.visus.uni-stuttgart.de/institut/team/arbeitsgruppe/arbeitsgruppe-prof.-sedlmair/, Website Lab
https://visvar.github.io/, Website Visvar},
doi = {10.1145/3491101.3519822},
year  = {2022},
date = {2022-04-30},
abstract = {Virtual avatars are widely used for collaborating in virtual environments. Yet, often these avatars lack expressiveness to determine a state of mind. Prior work has demonstrated effective usage of determining emotions and animated lip movement through analyzing mere audio tracks of spoken words. To provide this information on a virtual avatar, we created a natural audio data set consisting of 17 audio files from which we then extracted the underlying emotion and lip movement. To conduct a pilot study, we developed a prototypical system that displays the extracted visual parameters and then maps them on a virtual avatar while playing the corresponding audio file. We tested the system with 5 participants in two conditions: (i) while seeing the virtual avatar only an audio file was played and (ii). In addition to the audio file, the extracted facial visual parameters were displayed on the virtual avatar. Our results suggest the validity of using additional visual parameters in the avatars' face as it helps to determine emotions. We conclude with a brief discussion on the outcomes and their implications on future work.},
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022MatviienkoEScootAR,
title = {E-ScootAR: Exploring Unimodal Warnings for E-Scooter Riders in Augmented Reality},
author = {Andrii Matviienko (Technical University of Darmstadt) and Florian Müller (LMU Munich) and Dominik Schön (Technical University of Darmstadt) and Régis Fayard (Technical University of Darmstadt) and Salar Abaspur (Technical University of Darmstadt) and Yi Li (Technical University of Darmstadt) and Max Mühlhäuser (Technical University of Darmstadt)},
url = {https://teamdarmstadt.de/, Website Lab
https://www.facebook.com/teamdarmstadt, Facebook Lab},
doi = {10.1145/3491101.3519831},
year  = {2022},
date = {2022-04-30},
abstract = {Micro-mobility is becoming a more popular means of transportation. However, this increased popularity brings its challenges. In particular, the accident rates for E-Scooter riders increase, which endangers the riders and other road users. In this paper, we explore the idea of augmenting E-Scooters with unimodal warnings to prevent collisions with other road users, which include Augmented Reality (AR) notifications, vibrotactile feedback on the handlebar, and auditory signals in the AR glasses. We conducted an outdoor experiment (N = 13) using an Augmented Reality simulation and compared these types of warnings in terms of reaction time, accident rate, and feeling of safety. Our results indicate that AR and auditory warnings lead to shorter reaction times, have a better perception, and create a better feeling of safety than vibrotactile warnings. Moreover, auditory signals have a higher acceptance by the riders compared to the other two types of warnings.},
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022MatviienkoBikeAR,
title = {BikeAR: Understanding Cyclists’ Crossing Decision-Making at Uncontrolled Intersections using Augmented Reality},
author = {Andrii Matviienko (Technical University of Darmstadt) and Florian Müller (LMU Munich) and Dominik Schön (Technical University of Darmstadt) and Paul Seesemann (Technical University of Darmstadt) and Sebastian Günther (Technical University of Darmstadt) and Max Mühlhäuser (Technical University of Darmstadt)},
url = {https://teamdarmstadt.de/, Website Lab
https://www.facebook.com/teamdarmstadt, Facebook Lab},
doi = {10.1145/3491102.3517560},
year  = {2022},
date = {2022-04-30},
abstract = {Cycling has become increasingly popular as a means of transportation. However, cyclists remain a highly vulnerable group of road users. According to accident reports, one of the most dangerous situations for cyclists are uncontrolled intersections, where cars approach from both directions. To address this issue and assist cyclists in crossing decision-making at uncontrolled intersections, we designed two visualizations that: (1) highlight occluded cars through an X-ray vision and (2) depict the remaining time the intersection is safe to cross via a Countdown. To investigate the efficiency of these visualizations, we proposed an Augmented Reality simulation as a novel evaluation method, in which the above visualizations are represented as AR, and conducted a controlled experiment with 24 participants indoors. We found that the X-ray ensures a fast selection of shorter gaps between cars, while the Countdown facilitates a feeling of safety and provides a better intersection overview.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022MatviienkoVRSickness,
title = {Reducing Virtual Reality Sickness for Cyclists in VR Bicycle Simulators},
author = {Andrii Matviienko (Technical University of Darmstadt) and Florian Müller (LMU Munich) and Marcel Zickler (Technical University of Darmstadt) and Lisa Gasche (Technical University of Darmstadt) and Julia Abels (Technical University of Darmstadt) and Till Steinert (Technical University of Darmstadt) and Max Mühlhäuser (Technical University of Darmstadt)},
url = {https://teamdarmstadt.de/, Website Lab
https://www.facebook.com/teamdarmstadt, Facebook Lab},
doi = {10.1145/3491102.3501959},
year  = {2022},
date = {2022-04-30},
abstract = {Virtual Reality (VR) bicycle simulations aim to recreate the feeling of riding a bicycle and are commonly used in many application areas. However, current solutions still create mismatches between the visuals and physical movement, which causes VR sickness and diminishes the cycling experience. To reduce VR sickness in bicycle simulators, we conducted two controlled lab experiments addressing two main causes of VR sickness: (1) steering methods and (2) cycling trajectory. In the first experiment (N = 18) we compared handlebar, HMD, and upper-body steering methods. In the second experiment (N = 24) we explored three types of movement in VR (1D, 2D, and 3D trajectories) and three countermeasures (airflow, vibration, and dynamic Field-of-View) to reduce VR sickness. We found that handlebar steering leads to the lowest VR sickness without decreasing cycling performance and airflow suggests to be the most promising method to reduce VR sickness for all three types of trajectories.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022MatviienkoSkyPort,
title = {SkyPort: Investigating 3D Teleportation Methods in Virtual Environments},
author = {Andrii Matviienko (Technical University of Darmstadt) and Florian Müller (LMU Munich) and Martin Schmitz (Technical University of Darmstadt) and Marco Fendrich (Technical University of Darmstadt) and Max Mühlhäuser (Technical University of Darmstadt)},
url = {https://teamdarmstadt.de/, Website Lab
https://www.facebook.com/teamdarmstadt, Facebook Lab},
doi = {10.1145/3491102.3501983},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Teleportation has become the de facto standard of locomotion in Virtual Reality (VR) environments. However, teleportation with parabolic and linear target aiming methods is restricted to horizontal 2D planes and it is unknown how they transfer to the 3D space. In this paper, we propose six 3D teleportation methods in virtual environments based on the combination of two existing aiming methods (linear and parabolic) and three types of transitioning to a target (instant, interpolated and continuous). To investigate the performance of the proposed teleportation methods, we conducted a controlled lab experiment (N = 24) with a mid-air coin collection task to assess accuracy, efficiency and VR sickness. We discovered that the linear aiming method leads to faster and more accurate target selection. Moreover, a combination of linear aiming and instant transitioning leads to the highest efficiency and accuracy without increasing VR sickness.},
keywords = {Full Paper, Honorable Mention},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022PutzeBrainSignals,
title = {Understanding HCI Practices and Challenges of Experiment Reporting with Brain Signals: Towards Reproducibility and Reuse},
author = {Felix Putze (University of Bremen) and Susanne Putze (University of Bremen) and Merle Sagehorn (University of Bremen) and Christopher Micek (Worcester Polytechnic Institute) and Erin Solovey (Worcester Polytechnic Institute)},
url = {https://www.uni-bremen.de/csl, Website Lab
https://youtu.be/xH5pgnMKrZ8, YouTube - Video Figure},
doi = {10.1145/3490554},
year  = {2022},
date = {2022-04-30},
abstract = {In HCI, there has been a push towards open science, but to date, this has not happened consistently for HCI research utilizing brain signals due to unclear guidelines to support reuse and reproduction. To understand existing practices in the field, this paper examines 110 publications, exploring domains, applications, modalities, mental states and processes, and more. This analysis reveals variance in how authors report experiments, which creates challenges to understand, reproduce, and build on that research. It then describes an overarching experiment model that provides a formal structure for reporting HCI research with brain signals, including definitions, terminology, categories, and examples for each aspect. Multiple distinct reporting styles were identified through factor analysis and tied to different types of research. The paper concludes with recommendations and discusses future challenges. This creates actionable items from the abstract model and empirical observations to make HCI research with brain signals more reproducible and reusable.},
keywords = {Journal},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022MarkyMusic,
title = {Intelligent Music Interfaces: When Interactive Assistance and Augmentation Meet Musical Instruments},
author = {Karola Marky (University of Glasgow) and Annika Kilian (LMU Munich) and Andreas Weiss (Musikschule Schallkultur) and Jakob Karolus (LMU Munich) and Matthias Hoppe (LMU Munich) and Pawel W. Wozniak (Chalmers University of Technology) and Max Mühlhäuser (TU Darmstadt) and Thomas Kosch (Utrecht University)},
url = {https://teamdarmstadt.de/, Website Lab},
doi = {10.1145/3491101.3503743},
year  = {2022},
date = {2022-04-30},
abstract = {The interactive augmentation of musical instruments to foster self-expressiveness and learning has a rich history. Over the past decades, the incorporation of interactive technologies into musical instruments emerged into a new research field requiring strong collaboration between different disciplines. The workshop "Intelligent Music Interfaces" consequently covers a wide range of musical research subjects and directions, including (a) current challenges in musical learning, (b) prototyping for improvements, (c) new means of musical expression, and (d) evaluation of the solutions.},
keywords = {Workshop},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022QueckSpiderClip,
title = {SpiderClip: Towards an Open Source System for Wearable Device Simulation in Virtual Reality},
author = {Dirk Queck (Technische Universität Kaiserslautern TUK) and Iannis Albert (Technische Universität Kaiserslautern TUK, University of Bremen) and Philipp Zimmer (Technische Universität Kaiserslautern TUK) and Nicole Burkard (Technische Universität Kaiserslautern TUK) and Georg Volkmar (Digital Media Lab, University of Bremen) and Bastian Dänekas (Digital Media Lab, University of Bremen) and Rainer Malaka (Digital Media Lab, University of Bremen) and Marc Herrlich (Technische Universität Kaiserslautern TUK, DFKI)},
url = {https://sge.eit.uni-kl.de/startseite, Website Lab},
doi = {10.1145/3491101.3519758},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Smartwatches and fitness trackers integrate different sensors from inertial measurement units to heart rate sensors in a very compact and affordable form factor. This makes them interesting and relevant research tools. One potential application domain is virtual reality, e.g., for health related applications such as exergames or simulation approaches. However, commercial devices complicate and limit the collection of raw and real-time data, suffer from privacy issues and are not tailored to using them with VR tracking systems. We address these issues with an open source design to facilitate the construction of VR-enabled wearables for conducting scientific experiments. Our work is motivated by research in mixed realities in pervasive computing environments. We introduce our system and present a proof-of-concept study with 17 participants. Our results show that the wearable reliably measures high-quality data comparable to commercially available fitness trackers and that it does not impede movements or interfere with VR tracking.},
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022AlizadehAppropriation,
title = {On Appropriation and Nostalgic Reminiscence of Technology },
author = {Fatemeh Alizadeh (Universität Siegen) and Aikaterini Mniestri (Universität Siegen) and Alarith Uhde (Universität Siegen) and Gunnar Stevens (Universität Siegen) },
url = {https://www.verbraucherinformatik.de/en/home-en/, Website Lab},
doi = {10.1145/3491101.3519676},
year  = {2022},
date = {2022-04-30},
abstract = {Technological objects present themselves as necessary, only to become obsolete faster than ever before. This phenomenon has led to a population that experiences a plethora of technological objects and interfaces as they age, which become associated with certain stages of life and disappear thereafter. Noting the expanding body of literature within HCI about appropriation, our work pinpoints an area that needs more attention, “outdated technologies.” In other words, we assert that design practices can profit as much from imaginaries of the future as they can from reassessing artefacts from the past in a critical way. In a two-week fieldwork with 37 HCI students, we gathered an international collection of nostalgic devices from 14 different countries to investigate what memories people still have of older technologies and the ways in which these memories reveal normative and accidental use of technological objects. We found that participants primarily remembered older technologies with positive connotations and shared memories of how they had adapted and appropriated these technologies, rather than normative uses. We refer to this phenomenon as nostalgic reminiscence. In the future, we would like to develop this concept further by discussing how nostalgic reminiscence can be operationalized to stimulate speculative design in the present.},
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022KraussXRPrototyping,
title = {Elements of XR Prototyping: Characterizing the Role and Use of Prototypes in Augmented and Virtual Reality Design},
author = {Veronika Krauß (Universität Siegen) and Michael Nebeling (University of Michigan) and Florian Jasche (Universität Siegen) and Alexander Boden (Hochschule Bonn-Rhein-Sieg, Fraunhofer FIT)},
url = {www.verbraucherinformatik.de, Website Lab},
doi = {10.1145/3491102.3517714},
year  = {2022},
date = {2022-04-30},
abstract = {Current research in augmented, virtual, and mixed reality (XR) reveals a lack of tool support for designing and, in particular, prototyping XR applications. While recent tools research is often motivated by studying the requirements of non-technical designers and end-user developers, the perspective of industry practitioners is less well understood. In an interview study with 17 practitioners from different industry sectors working on professional XR projects, we establish the design practices in industry, from early project stages to the final product. To better understand XR design challenges, we characterize the different methods and tools used for prototyping and describe the role and use of key prototypes in the different projects. We extract common elements of XR prototyping, elaborating on the tools and materials used for prototyping and establishing different views on the notion of fidelity. Finally, we highlight key issues for future XR tools research.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022VoelkelChatbots,
title = {User Perceptions of Extraversion in Chatbots after Repeated Use},
author = {Sarah Theres Völkel (LMU Munich) and Ramona Schoedel (LMU Munich) and Lale Kaya (LMU Munich) and Sven Mayer (LMU Munich)},
url = {http://www.medien.ifi.lmu.de, Website Lab
https://youtu.be/brDKyt56_iU, YouTube - Teaser Video},
doi = {10.1145/3491102.3502058},
year  = {2022},
date = {2022-04-30},
abstract = {Whilst imbuing robots and voice assistants with personality has been found to positively impact user experience, little is known about user perceptions of personality in purely text-based chatbots. In a within-subjects study, we asked N=34 participants to interact with three chatbots with different levels of Extraversion (extraverted, average, introverted), each over the course of four days. We systematically varied the chatbots' responses to manipulate Extraversion based on work in the psycholinguistics of human behaviour. Our results show that participants perceived the extraverted and average chatbots as such, whereas verbal cues transferred from human behaviour were insufficient to create an introverted chatbot. Whilst most participants preferred interacting with the extraverted chatbot, participants engaged significantly more with the introverted chatbot as indicated by the users' average number of written words. We discuss implications for researchers and practitioners on how to design chatbot personalities that can adapt to user preferences.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022ZarghamThatWay,
title = {"I Want It That Way": Exploring Users' Customization and Personalization Preferences for Home Assistants},
author = {Nima Zargham (Digital Media Lab, University of Bremen) and Dmitry Alexandrovsky (Digital Media Lab, University of Bremen) and Jan Erich (Digital Media Lab, University of Bremen) and Nina Wenig (Digital Media Lab, University of Bremen) and Rainer Malaka (Digital Media Lab, University of Bremen)},
url = {https://www.uni-bremen.de/dmlab/team, Website Lab},
doi = {10.1145/3491101.3519843},
year  = {2022},
date = {2022-04-30},
abstract = {Home assistants are becoming a widespread product, but they mostly come as a compact device and offer very few customization and personalization features, which often leads to dissatisfaction. With the technological advancements, these systems are becoming more adaptable to the users' needs and can better imitate a human personality. To achieve that efficiently, understanding how different users envision their desired assistant is crucial. To identify people's customization and personalization preferences and their desired personality for a home assistant, we designed a set of storyboards depicting a variety of possible features in a domestic setting and conducted a user study (N=15), including a series of semi-structured interviews. Our quantitative results suggest that users prefer an agent which is highly agreeable and has higher conscientiousness and emotional stability. Furthermore, we discuss users' customization and personalization preferences for a home assistant, which could be considered when designing the future generation of home assistants.},
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022ZarghamCatch,
title = {"I Didn't Catch That, But I'll Try My Best'': Anticipatory Error Handling in a Voice Controlled Game},
author = {Nima Zargham (Digital Media Lab, University of Bremen) and Johannes Pfau (Digital Media Lab, University of Bremen) and Tobias Schnackenberg (Digital Media Lab, University of Bremen) and Rainer Malaka (Digital Media Lab, University of Bremen)},
url = {https://www.uni-bremen.de/dmlab/team, Website Lab
https://www.youtube.com/watch?v=9LSZK8TG7C4, YouTube - Video Figure},
doi = {10.1145/3491102.3502115},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Advances in speech recognition, language processing and natural interaction have led to an increased industrial and academic interest. While the robustness and usability of such systems are steadily increasing, speech-based systems are still susceptible to recognition errors. This makes intelligent error handling of utmost importance for the success of those systems. In this work, we integrated anticipatory error handling for a voice-controlled video game where the game would perform a locally optimized action in respect to goal completion and obstacle avoidance, when a command is not recognized. We evaluated the user experience of our approach versus traditional, repetition-based error handling (N=34). Our results indicate that implementing anticipatory error handling can improve the usability of a system, if it follows the intention of the user. Otherwise, it impairs the user experience, even when deciding for technically optimal decisions.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022ElAgroudySharedMemories,
title = {How do Users Expect their Smart Memory Vaults to Utilize Their Shared Memories? },
author = {Passant ElAgroudy (LMU Munich) and Ms. Mennatallah Saleh (Hamm-Lippstadt University of Applied Science, Technical University Berlin) and Christian Sturm (Hamm-Lippstadt University of Applied Sciences) and Albrecht Schmidt (LMU Munich)},
year  = {2022},
date = {2022-04-30},
abstract = {Social media (SM) is a popular accessible form of smart memory vaults. Prior work shows that users are still unable to understand how their shared memories are used by smart systems to create Smart Interactions involving Personal Memories (SIPMs). This can lead to negative social repercussions such as cyberbullying. This work investigates the most memorable SIPMs on Facebook for Egyptian users and their impact on platform usage. We conducted an online survey (N=53) requesting critical incident reports about surprising Facebook SIPMs. The most remembered SIPMs were: customizing advertisements, cuing offline interactions, sharing data with third parties and personalizing the newsfeed. Our results suggest that SIPMs, particularly customized advertisements act as ambient memory augmentation solutions to the users’ shared memories. Additionally, negative platform perception does not necessarily translate into reduction of platform usage. Our work inspires the discussion about users expectations towards ambient usage of their data on smart memory vaults.},
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022CannanureBorders,
title = {HCI Across Borders: Navigating the shifting borders in CHI},
author = {Vikram Kamath Cannanure (Carnegie Mellon University) and Cuauhtémoc Rivera-Loaiza (Universidad Michoacana) and Annu Sible Prabhakar (University of Cincinnati) and Rama Adithya Varanasi (Cornell University) and Anupriya Tuli (IIIT-Delhi) and Dilrukshi Gamage (Tokyo Institute of Technology) and Faria Noor (Bentley University) and Naveena Karusala (University of Washington) and David Nemer (University of Virginia) and Dipto Das (University of Colorado Boulder) and Susan Dray (Dray & Associates) and Christian Sturm (Hamm-Lippstadt University of Applied Sciences) and Neha Kumar (Georgia Tech)},
url = {https://hcixb.org/, Website Workshop},
year  = {2022},
date = {2022-04-30},
abstract = {HCI research has led to major innovations used by large and diverse audiences in different parts of the world. However, a recent meta-analysis found that research at CHI is still highly (73%) concentrated in western contexts. HCI Across Borders (HCIxB) has gathered a diverse audience to expand the borders within CHI over the past six years. For CHI 2022, we expect to regroup to reflect on shifting boundaries from CHI’s past and emerging challenges in research, teaching, and practice during the Covid-19 pandemic.},
keywords = {Workshop},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022MuenderHapticFidelity,
title = {Haptic Fidelity Framework: Defining the Factors of Realistic Haptic Feedback for Virtual Reality},
author = {Thomas Muender (University of Bremen) and Michael Bonfert (University of Bremen) and Anke V. Reinschluessel (University of Bremen) and Rainer Malaka (University of Bremen) and Tanja Döring (University of Bremen)},
url = {http://dm.tzi.de/, Website Lab
https://twitter.com/dmlabbremen, Twitter Lab
https://youtu.be/chEEus4K2Gs, YouTube - Teaser Video},
doi = {10.1145/3491102.3501953},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Providing haptic feedback in virtual reality to make the experience more realistic has become a strong focus of research in recent years. The resulting haptic feedback systems differ greatly in their technologies, feedback possibilities, and overall realism making it challenging to compare different systems. We propose the Haptic Fidelity Framework providing the means to describe, understand and compare haptic feedback systems. The framework locates a system in the spectrum of providing realistic or abstract haptic feedback using the Haptic Fidelity dimension. It comprises 14 criteria that either describe foundational or limiting factors. A second Versatility dimension captures the current trade-off between highly realistic but application-specific and more abstract but widely applicable feedback. To validate the framework, we compared the Haptic Fidelity score to the perceived feedback realism of evaluations from 38 papers and found a strong correlation suggesting the framework accurately describes the realism of haptic feedback.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022PourjafarianSurfacesPrinter,
title = {Print-A-Sketch: A Handheld Printer for Physical Sketching of Circuits and Sensors on Everyday Surfaces},
author = {Narjes Pourjafarian (Saarland University, Saarland Informatics Campus, Saarbrücken, Germany) and Marion Koelle (Saarland University, Saarland Informatics Campus, Saarbrücken, Germany) and Fjolla Mjaku (Saarland University, Saarland Informatics Campus, Saarbrücken, Germany) and Paul Strohmeier (Max Planck Institute for Informatics, Saarland University, Saarland Informatics Campus, Saarbrücken, Germany) and Jürgen Steimle},
url = {https://hci.cs.uni-saarland.de/, Website Lab
https://youtu.be/GbC9pKPzhF4, YouTube - Teaser Video
https://youtu.be/nnvOC-OtINw, YouTube - Video Figure},
doi = {10.1145/3491102.3502074},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {We present Print-A-Sketch, an open-source handheld printer prototype for sketching circuits and sensors. Print-A-Sketch combines desirable properties from free-hand sketching and functional electronic printing. Manual human control of large strokes is augmented with computer control of fine detail. Shared control of Print-A-Sketch supports sketching interactive interfaces on everyday objects -- including many objects with materials or sizes which otherwise are difficult to print on. We present an overview of challenges involved in such a system and show how these can be addressed using context-aware, dynamic printing. Continuous sensing ensures quality prints by adjusting inking-rate to hand movement and material properties. Continuous sensing also enables the print to adapt to previously printed traces to support incremental and iterative sketching. Results show good conductivity on many materials and high spatial precision, supporting on-the-fly creation of functional interfaces.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022PflegingAutomatedVehiclesWellbeing,
title = {Automated Vehicles as a Space for Work & Wellbeing},
author = {Bastian Pfleging (TU Bergakademie Freiberg) and Andrew L Kun (University of New Hampshire) and Orit Shaer (Wellesley College)

},
url = {https://tu-freiberg.de/en/ubisys, Website Lab},
doi = {10.1145/3491101.3503766},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {The objective of this CHI course is to provide CHI attendees with an introduction and overview of the rapidly evolving field of automotive user interfaces (AutomotiveUI). The course will focus on UI aspects in the transition towards automated driving. In particular, we will also discuss the opportunities of cars as a new space for non-driving-related activities, such as work, relaxation, and play. For newcomers and experts of other HCI fields, we will present the special properties of this field of HCI and provide an overview of new opportunities, but also general design and evaluation aspects of novel automotive user interfaces. },
note = {Course changed to online for now (original abstract says in-person course)},
keywords = {Course},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022DangGANSlider,
title = {GANSlider: How Users Control Generative Models for Images using Multiple Sliders with and without Feedforward Information},
author = {Hai Dang (University of Bayreuth) and Lukas Mecke (LMU Munich, UniBW Munich) and Daniel Buschek (University of Bayreuth)},
url = {https://www.hciai.uni-bayreuth.de/, Website Lab},
doi = {10.1145/3491102.3502141},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {We investigate how multiple sliders with and without feedforward visualizations influence users' control of generative models. In an online study (N=138), we collected a dataset of people interacting with a generative adversarial network (StyleGAN2) in an image reconstruction task. We found that more control dimensions (sliders) significantly increase task difficulty and user actions. Visual feedforward partly mitigates this by enabling more goal-directed interaction. However, we found no evidence of faster or more accurate task performance. This indicates a tradeoff between feedforward detail and implied cognitive costs, such as attention. Moreover, we found that visualizations alone are not always sufficient for users to understand individual control dimensions. Our study quantifies fundamental UI design factors and resulting interaction behavior in this context, revealing opportunities for improvement in the UI design for interactive applications of generative models. We close by discussing design directions and further aspects.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022RivuRemoteVRStudies,
title = {Remote VR Studies: A Framework for Running Virtual Reality Studies Remotely Via Participant-Owned HMDs},
author = {R. Rivu (Bundeswehr University Munich) and V. Mäkelä (University of Waterloo, Bundeswehr University Munich) and S. Prange (Bundeswehr University Munich) and S. Rodriguez (Bundeswehr University Munich) and R. Piening(LMU Munich) and Y. Zhou (LMU Munich) and K. Köhle (LMU Munich) and K. Pfeuffer (Bundeswehr University Munich) and Y. Abdelrahman(Bundeswehr University Munich) and M. Hoppe(LMU Munich) and A. Schmidt (LMU Munich) and F. Alt (Bundeswehr University Munich)},
url = {https://www.unibw.de/usable-security-and-privacy-en, Website Lab},
doi = {10.1145/3472617},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {We investigate opportunities and challenges of running virtual reality (VR) studies remotely. Today, many consumers own head-mounted displays (HMDs), allowing them to participate in scientific studies from their homes using their own equipment. Researchers can benefit from this approach by being able to recruit study populations normally out of their reach, and to conduct research at times when it is difficult to get people into the lab (cf. the COVID pandemic). In an initial online survey (N=227), we assessed HMD owners' demographics, their VR setups and their attitudes towards remote participation. We then identified different approaches to running remote studies and conducted two case studies for an in-depth understanding. We synthesize our findings into a framework for remote VR studies, discuss strengths and weaknesses of the different approaches, and derive best practices. Our work is valuable for HCI researchers conducting VR studies outside labs.},
keywords = {Journal},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022RixenPersonalInformationAR,
title = {Consent in the Age of AR: Investigating The Comfort With Displaying Personal Information in Augmented Reality},
author = {Jan Ole Rixen (Institute of Media Informatics, Ulm University) and Mark Colley (Institute of Media Informatics, Ulm University) and Ali Askari (Institute of Media Informatics, Ulm University) and Jan Gugenheimer (Télécom Paris - LTCI, Institut Polytechnique de Paris) and Enrico Rukzio (Institute of Media Informatics, Ulm University)},
doi = {10.1145/3491102.3502140},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Social Media (SM) has shown that we adapt our communication and disclosure behaviors to available technological opportunities. Head-mounted Augmented Reality (AR) will soon allow to effortlessly display the information we disclosed not isolated from our physical presence (e.g., on a smartphone) but visually attached to the human body. In this work, we explore how the medium (AR vs.Smartphone), our role (being augmented vs. augmenting), and characteristics of information types (e.g., level of intimacy, self-disclosed vs. non-self-disclosed) impact the users’ comfort when displaying personal information. Conducting an online survey (N=148), we found that AR technology and being augmented negatively impacted this comfort. Additionally, we report that AR mitigated the effects of information characteristics compared to those they had on smartphones. In light of our results, we discuss that information augmentation should be built on consent and openness, focusing more on the comfort of the augmented rather than the technological possibilities.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022SaadCovid19UsageAndAuthentication,
title = {Mask removal isn't always convenient in public! - The Impact of the Covid-19 Pandemic on Device Usage and User Authentication},
author = {Alia Saad (University of Duisburg-Essen) and Uwe Gruenefeld (University of Duisburg-Essen) and Lukas Mecke (Bundeswehr University Munich) and Marion Koelle (University of Duisburg-Essen) and Florian Alt (Bundeswehr University Munich) and Stefan Schneegass (University of Duisburg-Essen)},
url = {https://www.hci.wiwi.uni-due.de/en/profile/, Website Lab
https://www.facebook.com/HCIEssen/, Facebook Lab},
doi = {10.1145/3491101.3519804},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {The ongoing Covid-19 pandemic has impacted our everyday lives and demands everyone to take countermeasures such as wearing masks or disinfecting their hands. However, while previous work suggests that these countermeasures may profoundly impact biometric authentication, an investigation of the actual impact is still missing. Hence, in this work, we present our findings from an online survey (n=334) on experienced changes in device usage and failures of authentication. Our results show significant changes in personal and shared device usage, as well as a significant increase in experienced failures when comparing the present situation to before the Covid-19 pandemic. From our qualitative analysis of participants' responses, we derive potential reasons for these changes in device usage and increases in authentication failures. Our findings suggest that making authentication contactless is only one of the aspects relevant to encounter the novel challenges caused by the pandemic.},
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022GruenefeldVRception,
title = {VRception: Rapid Prototyping of Cross-Reality Systems in Virtual Reality},
author = {Uwe Gruenefeld (University of Duisburg-Essen) and Jonas Auda (University of Duisburg-Essen) and Florian Mathis (University of Glasgow, University of Edinburgh) and Stefan Schneegass (University of Duisburg-Essen) and Mohamed Khamis (University of Glasgow) and Jan Gugenheimer (Institut Polytechnique de Paris, Télécom Paris, LTCI) and and Sven Mayer (LMU Munich)},
url = {https://www.hci.wiwi.uni-due.de/, Website Lab
https://www.facebook.com/HCIEssen, Facebook Lab
https://1drv.ms/v/s!Avx0fb46Z9TNxK8sGhhe-VUt-QDIZA?e=Slw4GB, Teaser Video
https://1drv.ms/v/s!Avx0fb46Z9TNxK8klmFf1sh0avlT0A?e=AnLhgc, Video Figure},
doi = {10.1145/3491102.3501821},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Cross-reality systems empower users to transition along the reality-virtuality continuum or collaborate with others experiencing different manifestations of it. However, prototyping these systems is challenging, as it requires sophisticated technical skills, time, and often expensive hardware. We present VRception, a concept and toolkit for quick and easy prototyping of cross-reality systems. By simulating all levels of the reality-virtuality continuum entirely in Virtual Reality, our concept overcomes the asynchronicity of realities, eliminating technical obstacles. Our VRception toolkit leverages this concept to allow rapid prototyping of cross-reality systems and easy remixing of elements from all continuum levels. We replicated six cross-reality papers using our toolkit and presented them to their authors. Interviews with them revealed that our toolkit sufficiently replicates their core functionalities and allows quick iterations. Additionally, remote participants used our toolkit in pairs to collaboratively implement prototypes in about eight minutes that they would have otherwise expected to take days.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@bachelorthesis{2022ColleyEffectsAutomatedVehicles,
title = {Effects of Pedestrian Behavior, Time Pressure, and Repeated Exposure on Crossing Decisions in Front of Automated Vehicles Equipped with External Communication},
author = {Mark Colley (Institute of Media Informatics, Ulm University) and Elvedin Bajrovic (Institute of Media Informatics, Ulm University) and Enrico Rukzio (Institute of Media Informatics, Ulm University)},
url = {https://www.uni-ulm.de/en/in/mi/hci/, Website Lab
https://twitter.com/mi_uulm, Twitter Lab},
doi = {10.1145/3491102.3517571},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Automated vehicles are expected to substitute driver-pedestrian communication via LED strips or displays. This communication is expected to improve trust and the crossing process in general. However, numerous factors such as other pedestrians' behavior, perceived time pressure, or previous experience influence crossing decisions. Therefore, we report the results of a triply subdivided Virtual Reality study (N=18) evaluating these. Results show that external communication was perceived as hedonically pleasing, increased perceived safety and trust, and also that pedestrians' behavior affected participants' behavior. A timer did not alter crossing behavior, however, repeated exposure increased trust and reduced crossing times, showing a habituation effect. Our work helps better to integrate research on external communication in ecologically valid settings.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {bachelorthesis}
}
@inproceedings{2022MakhsadovVRySmart,
title = {VRySmart: a Framework for Embedding Smart Devices in Virtual Reality},
author = {Akhmajon Makhsadov (Saarland University & DFKI) and Donald Degraen (Saarland University & DFKI) and André Zenner (Saarland University & DFKI) and Felix Kosmalla (Saarland University & DFKI) and Kamila Mushkina (Saarland University) and Antonio Krüger (Saarland University & DFKI)},
url = {https://umtl.cs.uni-saarland.de/, Website Lab
https://twitter.com/umtl, Twitter Lab
https://youtu.be/jjV3OI1RRok, YouTube - Teaser Video
https://youtu.be/qPkUWzpyVe8, YouTube - Video Figure},
doi = {10.1145/3491101.3519717},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {As immersive virtual experiences find their way into our living room entertainment, they are becoming part of our daily technological consumption. However, state-of-the-art virtual reality (VR) remains disconnected from other digital devices in our environment, such as smartphones or tablets. As context switches between acting in the virtual environment and resolving external notifications negatively influence immersion, we look towards integrating smart devices into virtual experiences. To this aim, we present the VRySmart framework. Through either optical marker tracking or simultaneous localization and mapping (SLAM), embedded smart devices can be used as VR controllers with different levels of integration while their content is incorporated into the virtual context to support the plausibility of the illusion. To investigate user impressions, we conducted a study ($N = 10$) where participants used a smartphone in four different virtual scenarios. Participants positively assessed smart device usage in VR. We conclude by framing implications for future work.},
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022SchneiderSustainable,
title = {Sustainable Haptic Design: Improving Collaboration, Sharing, and Reuse in Haptic Design Research},
author = {Oliver Schneider (University of Waterloo) and Bruno Fruchard (Univ. Lille, Inria) and Dennis Wittchen (HTW Dresden) and Bibhushan Raj Joshi (University of Waterloo) and Georg Freitag (HTW Dresden) and Donald Degraen (Saarland University & DFKI) and Paul Strohmeier (Sensorimotor Interaction, MPI)},
url = {https://umtl.cs.uni-saarland.de/, Website Lab
https://twitter.com/umtl, Twitter Lab},
doi = {10.1145/3491101.3503734},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Haptic devices have been around for decades, providing critical information, usability benefits and improved experiences across tasks from surgical operations to playful applications in Mixed Reality. We see more and more software and hardware solutions emerging that provide design tools, design approaches and platforms, both in academia and industry. However, we believe that designers often re-invent the wheel, and must spend an inordinate amount of time doing their work, which is not sustainable for long-term research. This workshop aims at gathering people from academia and industry to provide a common ground to discuss various insights on and visions of the field. We aim to bring together the various strands of haptics -- devices, software, and design -- to assess the current state-of-the-art and propose an agenda towards haptics as a united design discipline. We expect the outcome of the workshop to be a comprehensive overview of existing tools and approaches, along with recommendations on how to move the field forward, together.},
keywords = {Workshop},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022BrockerActuated,
title = {Actuated Materials and Soft Robotics Strategies for Human Computer Interaction Design},
author = {Anke Brocker (RWTH Aachen University, Aachen, Germany) and Dr. Jose A. Barreiros (Cornell University, Ithaca, New York, United States) and
Ali Shtarbanov (MIT Media Lab, MIT, Cambridge, Massachusetts, United States) and Kristian Gohlke (Bauhaus-Universität Weimar, Weimar, Germany) and Ozgun Kilic Afsar (Media Technology & Interaction Design, KTH Royal Institute of Technology, Stockholm, Sweden; MIT Media Lab, MIT, Cambridge, Massachusetts, United States) and Sören Schröder( RWTH Aachen University, Aachen, Germany)},
url = {https://hci.rwth-aachen.de, Website Lab},
doi = {10.1145/3491101.3503711},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {The fields of programmable matter, actuated materials, and Soft Robotics are becoming increasingly more relevant for the design of novel applications, interfaces, and user experiences in the domain of Human-Computer Interaction (HCI). These research fields often use soft, flexible materials with elastic actuation mechanisms to build systems that are more adaptable, compliant, and suitable for a very broad range of environments. However, at the intersection between HCI and the aforementioned domains, there are numerous challenges related to fabrication methods, development tools, resource availability, nomenclature, design for inclusion, etc. This workshop aims to explore how to make Soft Robotics more accessible to both researchers and nonresearchers alike. We will (1) investigate and identify the various difficulties people face when developing HCI applications that require the transfer of knowledge from those other domains, and (2) discuss possible solutions and visions on how to overcome those difficulties.},
keywords = {Workshop},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022BrockerSoRoCAD,
title = {SoRoCAD: A Design Tool for the Building Blocks of Pneumatic Soft Robotics},
author = {Anke Brocker (RWTH Aachen University, Aachen, Germany) andJakob Strüver (RWTH Aachen University, Aachen, Germany) and Simon Voelker (RWTH Aachen University, Aachen, Germany) and Jan Borchers (RWTH Aachen University, Aachen, Germany)},
url = {https://hci.rwth-aachen.de, Website Lab
https://www.youtube.com/watch?v=sEZgc8XfHls&list=PLABNOB9DXl_2VOtkDAsxvoXDQGHTP-pC5&index=2, YouTube - Teaser Video
https://www.youtube.com/watch?v=qS7n__a-HPA&list=PLABNOB9DXl_2VOtkDAsxvoXDQGHTP-pC5&index=1, YouTube - Video Figure},
doi = {10.1145/3491101.3519770},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Soft robotics uses soft, flexible materials and elastic actuation mechanisms to create systems that are more adaptable and tolerant to unknown environments, and safer for human-machine interaction, than rigid robots. Pneumatic soft robots can be fabricated using more affordable materials compared to traditional robots and make use of technologies such as 3D printing, making them an attractive choice for research and DIY projects. However, their design is still highly unintuitive, and at up to two days, design iterations can take prohibitively long: The behavior of, e.g., a pneumatic silicone gripper only becomes apparent after designing and 3D printing its mold, casting, curing, assembling, and testing it. We introduce SoRoCAD, a design tool supporting a Maker-friendly soft robotics design and fabrication pipeline that incorporates simulating the final actuation into the design process.},
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022DoellingerMindandBody,
title = {Virtual Reality for Mind and Body: Does the Sense of Embodiment Towards a Virtual Body Affect Physical Body Awareness?},
author = {Nina Döllinger (University of Würzburg, Human-Technology Systems) and Erik Wolf (University of Würzburg, Human-Computer Interaction) and David Mal (University of Würzburg, Human-Computer Interaction) and Nico Erdmannsdörfer (University of Würzburg, Human-Technology Systems) and Mario Botsch (TU Dortmund, Computer Graphics Group) and Marc Erich Latoschik (University of Würzburg, Human-Computer Interaction) and Carolin Wienrich (University of Würzburg, Human-Technology Systems)},
url = {https://www.mcm.uni-wuerzburg.de/mts/, Website Lab},
doi = {10.1145/3491101.3519613},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Mind-body therapies aim to improve health by combining physical and mental exercises. Recent developments tend to incorporate virtual reality (VR) into their design and execution, but there is a lack of research concerning the inclusion of virtual bodies and their effect on body awareness in these designs. In this study, 24 participants performed in-VR body awareness movement tasks in front of a virtual mirror while embodying a photorealistic, personalized avatar. Subsequently, they performed a heartbeat counting task and rated their perceived body awareness and sense of embodiment towards the avatar. We found a significant relationship between sense of embodiment and self-reported body awareness but not between sense of embodiment and heartbeat counting. Future work can build on these findings and further explore the relationship between avatar embodiment and body awareness.},
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022ReipschlaegerAvatAR,
title = {AvatAR: An Immersive Analysis Environment for Human Motion Data Combining Interactive 3D Avatars and Trajectories},
author = {Patrick Reipschläger (Autodesk Research, Toronto, Ontario, Canada; Technische Universität Dresden Dresden, Germany) and Frederik Brudy (Autodesk Research, Toronto, Ontario, Canada) and Raimund Dachselt (Technische Universität Dresden Dresden, Germany) and Justin Matejka (Autodesk Research, Toronto, Ontario, Canada) and George Fitzmaurice (Autodesk Research, Toronto, Ontario, Canada) and Fraser Anderson (Autodesk Research, Toronto, Ontario, Canada)},
url = {https://www.imld.de, Website Lab},
doi = {10.1145/3491102.3517676},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Analysis of human motion data can reveal valuable insights about the utilization of space and interaction of humans with their environment. To support this, we present AvatAR, an immersive analysis environment for the in-situ visualization of human motion data, that combines 3D trajectories, virtual avatars of people’s movement, and a detailed representation of their posture. Additionally, we describe how to embed visualizations directly into the environment, showing what a person looked at or what surfaces they touched, and how the avatar’s body parts can be used to access and manipulate those visualizations. AvatAR combines an AR HMD with a tablet to provide both mid-air and touch interaction for system control, as well as an additional overview to help users navigate the environment. We implemented a prototype and present several scenarios to show that AvatAR can enhance the analysis of human motion data by making data not only explorable, but experienceable.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022HuangProxemics,
title = {Proxemics for Human-Agent Interaction in Augmented Reality},
author = {Ann Huang (LMU Munich) and Pascal Knierim (LMU Munich) and Francesco Chiossi (LMU Munich) and Lewis Chuang (Chair for Humans and Technology, Chemnitz University of Technology) and Robin Welsch (LMU Munich)},
url = {https://www.um.informatik.uni-muenchen.de/index.html, Website Lab
https://twitter.com/annnhuang, Twitter Author
https://youtu.be/1ULnYIqRqTE, YouTube - Teaser Video},
doi = {10.1145/3491102.3517593},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Augmented Reality (AR) embeds virtual content in physical spaces, including virtual agents that are known to exert a social presence on users. Existing design guidelines for AR rarely consider the social implications of an agent's personal space (PS) and that it can impact user behavior and arousal. We report an experiment (N=54) where participants interacted with agents in an AR art gallery scenario. When participants approached six virtual agents (i.e., two males, two females, a humanoid robot, and a pillar) to ask for directions, we found that participants respected the agents' PS and modulated interpersonal distances according to the human-like agents' perceived gender. When participants were instructed to walk through the agents, we observed heightened skin-conductance levels that indicate physiological arousal. These results are discussed in terms of proxemic theory that result in design recommendations for implementing pervasive AR experiences with virtual agents.},
keywords = {Full Paper},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022HirzleEyeStrain,
title = {Understanding, Addressing, and Analysing Digital Eye Strain in Virtual Reality Head-Mounted Displays},
author = {Teresa Hirzle (Ulm University) and Fabian Fischbach (Ulm University) and Julian Karlbauer (Ulm University) and Pascal Jansen (Ulm University) and Jan Gugenheimer (Télécom Paris) and Enrico Rukzio (Ulm University) and Andreas Bulling (University of Stuttgart)},
url = {https://www.uni-ulm.de/en/in/mi/hci/, Website Lab
https://twitter.com/mi_uulm, Twitter Lab
https://www.youtube.com/watch?v=ns2HwQ2p_hM, YouTube - Video Figure},
doi = {10.1145/3492802},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Digital eye strain (DES), caused by prolonged exposure to digital screens, stresses the visual system and negatively affects users’ well-being and productivity. While DES is well-studied in computer displays, its impact on users of virtual reality (VR) head-mounted displays (HMDs) is largely unexplored—despite that some of their key properties (e.g., the vergence-accommodation conflict) make VR-HMDs particularly prone. This work provides the first comprehensive investigation into DES in VR HMDs. We present results from a survey with 68 experienced users to understand DES symptoms in VR-HMDs. To help address DES, we investigate eye exercises resulting from survey answers and blue light filtering in three user studies (N = 71). Results demonstrate that eye exercises, but not blue light filtering, can effectively reduce DES. We conclude with an extensive analysis of the user studies and condense our findings in 10 key challenges that guide future work in this emerging research area.},
keywords = {Journal},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022MehrotraScent,
title = {The Scent of Collaboration: Exploring the Effect of Smell on Social Interactions},
author = {Siddharth Mehrotra (Delft University of Technology, Netherlands) and Anke Brocker (RWTH Aachen University, Germany) and Marianna Obrist (University College London, United Kingdom) and Jan Borchers (RWTH Aachen University, Germany)},
url = {https://hci.rwth-aachen.de, Website Lab
https://www.youtube.com/watch?v=ZRr-I57vNmk&list=PLABNOB9DXl_2VOtkDAsxvoXDQGHTP-pC5&index=3, YouTube - Teaser Video
https://www.youtube.com/watch?v=gtYYj3EOYKo&list=PLABNOB9DXl_2VOtkDAsxvoXDQGHTP-pC5&index=4, YouTube - Video Figure},
doi = {10.1145/3491101.3519632},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Social interactions are multisensory experiences. However, it is not well understood how technology-mediated smell can support social interactions, especially in collaborative tasks. To explore its effect on collaboration, we asked eleven pairs of users to work together on a writing task while wearing an interactive jewellery designed to emit scent in a controlled fashion. In a within-subjects experiment, participants were asked to collaboratively write a story about a standardized visual stimulus while exposed to with scent and without scent conditions. We analyzed video recordings and written stories using a combination of methods from HCI, psychology, sociology, and human communication research. We observed differences in both participants' communication and creation of insightful stories in the with scent condition. Furthermore, scent helped participants recover from communication breakdown even though they were unaware of it. We discuss the possible implications of our findings and the potential of technology-mediated scent for collaborative activities.},
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}
@inproceedings{2022WolfBreakfast,
title = {Spirituality at the Breakfast Table: Experiences of Christian Online Worship Services},
author = {Sara Wolf (Institute Human-Computer Media, JMU Würzburg, Germany) and Frauke Mörike (Department of Psychology and Ergonomics, TU Berlin, Germany) and Simon Luthe (Institute of Protestant Theology and Religious Education, JMU Würzburg, Germany) and Ilona Nord (Institute of Protestant Theology and Religious Education, JMU Würzburg, Germany) and Jörn Hurtienne (Chair of Psychological Ergonomics, JMU Würzburg, Germany)},
url = {https://www.mcm.uni-wuerzburg.de/psyergo/startseite/, Website Lab},
doi = {10.1145/3491101.3519856},
year  = {2022},
date = {2022-04-30},
urldate = {2022-04-30},
abstract = {Since the COVID-19 pandemics, we have witnessed an increase in online worship services. Nevertheless, HCI has little insight into how technological mediation influences religious experiences and how technology should be designed for use in religious contexts. Therefore, we see a unique opportunity to understand better real-world experiences of technology use in religious rituals and, more specifically, in online worship services. Inspired by contextual design, We virtually observed and interviewed eight persons during and after participation in online worship services. We identified a field of tension between faith, everyday life, individuality, and community. The data suggests that current online worship service systems do not account for believers' needs for community, faith, or extraordinariness. We discuss opportunities for future research and design, and aim to contribute to the understanding of online worship service experiences and the design of technology-mediated religious experiences. },
keywords = {Late Breaking Work},
pubstate = {published},
tppubtype = {inproceedings}
}